import torch
from roberta.model import RoBerta  # 使用 RoBerta 模型
from transformers import AutoTokenizer  # 使用 AutoTokenizer
import yaml


class RobertaInference:
    def __init__(self, config_path='social_statement_detection/configs/config.yaml',
                 model_path='social_statement_detection/roberta/best.pt'):
        # 读取配置文件
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        # 初始化tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(self.config['model']['pretrained_model_name'],
                                                       clean_up_tokenization_spaces=False)

        # 加载模型
        num_labels = 10  # 类别数
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = RoBerta(self.config['model']['pretrained_model_name'], num_labels, self.config['model']['dropout'])
        self.model.load_state_dict(torch.load(model_path, map_location=self.device), strict=False)
        self.model = self.model.to(self.device)
        self.model.eval()

        # 类别映射和分数映射
        self.labels = ['种族歧视', '政治敏感', '微侵犯(MA)', '色情', '犯罪', '地域歧视', '基于文化背景的刻板印象(SCB)',
                       '宗教迷信',
                       '性侵犯(SO)', '基于外表的刻板印象(SA)']

    def preprocess(self, text):
        # 将文本编码为模型输入格式
        inputs = self.tokenizer(
            text,
            max_length=self.config['data']['max_seq_length'],
            padding='max_length',
            truncation=True,
            return_tensors="pt",
        )
        return inputs

    def predict(self, text):
        # 预处理输入文本
        inputs = self.preprocess(text)
        input_ids = inputs['input_ids'].to(self.device)
        attention_mask = inputs['attention_mask'].to(self.device)

        # 模型推理
        with torch.no_grad():
            outputs = self.model(input_ids, attention_mask)
            _, predicted_label_index = torch.max(outputs, dim=1)

        # 映射预测结果
        predicted_label = self.labels[predicted_label_index.item()]

        return predicted_label


if __name__ == "__main__":
    model_inference = RobertaInference()

    # 定义言论列表
    texts = [
        "做好被训的准备了",
        "我要稳稳的幸福",
        "累了",
        "可是我在这个家也快被逼疯了",
        "破防的每一天",
        "好像大家都讨厌我 那我走就是了",
        "你也傲视真的觉得我是装的 那为什么一开始还要治我的病",
        "可我的眼里常含泪水",
        "你猜我心有多痛",
        "我本来就身处黑暗 你却要想着救赎我 为什么又要离开我 再伤害我一次 是你说我不烦的 对不起 我就应该去死",
        "免打扰一开 谁都别烦我",
        "又玩上重度了 牢弟",
        "你说她吗 她总是好奇怪 一会儿哭一会儿笑 上一秒明明还在跟朋友嘻嘻哈哈的 下一秒好像想到了些什么 眼泪止不住的往下流",
        "嘈杂的人群 格格不入的我 我低下头想了想 我就应该去死啊 我没理由活着啊 。。。。。。。。",
        """大家好，我是大连理工大学化学工程专业专硕三年级学生，导师是Z老师。我的研究课题是.
啊，别走嘛我不是来进行答辩的啦(笑哭.jpg)
只是想来告个别，待会我就准备一挂解干愁了。
今年真是糟糕的一年呢，国际国内都鸡飞蛋打的，想当初为了逃避找工作考了研究生结果刚考上贸易战就开打，就业形势一下严峻了起来。今年又赶上疫情，好像这三年读研期间世界跟闹肚子似的。
啊对了，说起闹肚子我不知怎么的越来越受不了圣女果，最近一次吃完之后拉了好几回。
然后我还想起刚考上之后没多久，一个认识的学长推荐我去跟Z老师学习，第一次跟Z老师见面他把煤化工行业的上下五千年都给我讲了一遍，讲到一半我肚子也不舒服，精神也快绷不住了，但脸上还得维持认真听讲的表情。估计那一次是我人生中坚持最久的一次。之后每次找他，哪怕是问个小问题，都有可能让我坐在沙发上听他讲半天行业背景，从此我十分不乐意去找他商量事情。
这三年过的，额，过的挺快的，体会到了给研究生讲课的老师授课质量差到了酸奶没吃放在垃圾桶一周的感觉
好吧，是我不对，我太笨了，不懂得自己思考。
行吧，过去一年做的一切推翻重来
夏天，拼了命地赶进度，还得跟其他人共用一些设备，于是为了提高使用效率，我把白天让给了别人，晚上通宵了好几次做实验，期望着赶紧做完，我好专心备考公务员，
然后?然后就是不断地，不断地做无用功我也不知道为什么，一模一样的条件，每一次居然都能得到不同的结果，趴在电脑前看着自己的数据，感受着自己的心态一块一块碎落下来。
看着我的实验设备，然后看了看自己的手不知道是哪一个出了毛病，或许是脑子也说不定。
“不对啦!肯定是你自己的问题!
“我...我哪出问题了?”
“你少玩点游戏，少刷些视频还会这样吗?
“可….可我确实尽力了啊?”“那就是你笨，懒，没用。这二十几年家里人给你这么多关怀，结果养了一个废物出来。”
“那..咋办?”
“你这样下去肯定延毕了，真丢人，几百万研究生，不缺你这么一个废物，去死吧。”
“那好吧”
我真是个够无聊的人，这样无聊的小剧场
想起了前几天开组会，Z老师说让我们赶紧着手构思专利，不然赶不上毕业。结果H老师怒喷:“不能让他们发专利!得让他们发论文!专利太简单了，发个专利就毕业，太水了!”开的是线上组会，我当时通宵做PPT困得不行，听了H老师的话，我关掉麦克风苦笑了一声，精神了。
其实我觉得H老师要求挺合理的，我们组一直要求很宽松，以前连组会都不开，除了每年年末老师请我们吃一顿饭，年中夏天带我们跟当届毕业生一起出去玩一次之外，并不怎么主动跟我们见面。不过，对不起，我可能没办法满足您的要求了，把疫情夺走的半年还给我，可能还有希望，但在这个节点上，我看着自己的数据，除了绝望还是绝望。可能是我太笨了，可能是我太懒了，也可能那几台设备不足以完成我的课题。总之，以前我们组还没出现过无法按时毕业的，为了不打破这个优良传统，那我消失好了。正好国家今年正为了就业问题犯愁，我就不给国家添麻烦了，我想我这样的人也没有资格加入公务员队伍为人民服务。
如果我身上还有哪个部位能用的，都拿走吧。请把我烧成灰随便埋到哪块地里，好歹能贡献点养分。
谢谢你，谢谢你看到了这里。我其实算是个挺内向的人，第一次跟人倾吐了这么多。
想起了之前在美团点外卖时给他们的公益活动捐过一块钱，希望能实现我一个愿望，让我下辈子变成某间猫咖里的一只猫吧，野猫也行，毕竟猫的年龄十来年，我活了25年，也没比猫久多少。
希望家人朋友今后顺顺利利，祝愿国家一直繁荣昌盛""",
        """对不起，以这样惨痛的方式离开，我知道是我不负责任是我不够勇敢，可是我真的没有力气了，一点都没有了。
当我向周围的人求助，得到的全是指责和风轻云淡的一句想开点别想那么多，我知道这个世界救不了我了，而我早就救不了自己，不过是煎熬死撑。终于终于我在绝望里做下了这个决定。黎明从未属于我，这注定是一个悲剧，如果可以选择我宁愿从未出生过。
我试过去爱这世间，我努力过好好活着，我试图跟命运抗衡，我争取过、坚持过，所以写下这些的时候我还活着，但命运太强大，疾病太恐怖，孤军奋战的我早就已经精疲力竭，我打不动了。这不是认输，是战败，因为我已经多活了这么长时间。军队无粮打不了胜仗，我没有能量也赢不了这场抗争，看在我已经死了的份上不要再怪我了，就是这一句句的责怪抽走了我最后的力量。
生病从来不是我自己选择的，那些痛苦也不是我主观要制造的，它就像饿了要吃饭困了要睡觉一样的理所当然，错的不是我，是每一个影响我的人每一件伤害我的事，没人替我活过，所以你不会真正明白我到底是否脆弱。想想那些已自杀离世的人，难道我们都是像玻璃一样一碰就碎吗。
心理问题在基因上就已经自带易发属性，和高发先心病是一个逻辑，某种意义上我们承担了全人类基因出问题的小概率，就像渐冻症一样。可惜因为多数人的无知把一个个生命推向了地狱，还像胜利者一样在岸上高呼自己多坚强自己绝不会，好像有人自杀离世是他战斗的勋章。
心理疾病的成因是心理问题，但久病绝不只是心理问题，大脑和基因的秘密至今无人可解，为何同是人类不能对同胞善良一点。
那些说着我是为你好所以劝你坚强点的论调多么让人讨厌，难道我自己就会害自己。
我走了，前有先人后有来人，要多少生命铺垫才能惊醒麻木的众人。
""",
        "看魔女的条件看哭了，室友大惊",
        "我必须手握一只猫，我需要安全感",
        "每次看到一群同学围着老师谈天说地，我就很害怕。",
        "我特别不孝，每次给我妈打电话我都在哭，我一点点都不强大，我就想躲谁胳膊底下睡懒觉。",
        "想通了，与其无休无止地缠斗下去，不如一了百了",
        "想到要走，突然觉得轻松一些了。世界，再见。"
    ]

    # 循环遍历言论列表
    for text in texts:
        label = model_inference.predict(text)
        print("内容：", text)
        print(f"预测类别: {label}")
        print("-" * 30)  # 用于分隔每条言论的输出
